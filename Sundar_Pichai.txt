it's inspiring to me. You grew up in India, whole family living in a humble two-room apartment,
very little, almost no access to technology. And from those humble beginnings,
you rose to lead a $2 trillion technology company.
So if you could travel back in time, and told that, let's say 12-year-old Sundar, that you're now leading
one of the largest companies in human history, what do you think that young kid would say? - I would've probably laughed it off.
You know, probably too farfetched to imagine or believe at that time.
- You would have to explain the internet first. - For sure. I mean, computers to me, at that time,
you know, I was 12 in 1984, so probably by then I'd started reading about them,
I hadn't seen one. - What was that place like? Take me to your childhood. - You know, I grew up in Chennai,
it's in south of India, it's a beautiful bustling city. Lots of people, lots of energy.
You know, simple life, definitely like fond memories of playing cricket
outside the home. We just used to play on the streets. All the neighborhood kids would come out,
and we would play till it got dark and we couldn't play anymore, barefoot.
Traffic would come, we would just stop the game, everything would drive through, and you would just continue playing, right?
Just to kind of get the visual in your head. You know, pre-computers, there's a lot of free time,
now that I think about it. Now you have to go and seek that quiet solitude or something.
Newspapers, books is how I gained access to the world's information at the time, if you will.
My grandfather was a big influence, he worked in the post office. He was so good with language,
his English, you know, his handwriting, till today, is the most beautiful handwriting I've ever seen.
He would write so clearly, he was so articulate, and so he kind of got me introduced into books,
he loved politics, so we could talk about anything. And, you know, that was there in my family throughout,
so lots of books, trashy books, good books, everything from Ayn Rand, to books on philosophy,
to stupid crime novels. So books was a big part of my life. But that kind of, this soul,
it's not surprising I ended up at Google, because Google's mission kind of always resonated deeply with me,
this access to knowledge, I was hungry for it. But definitely have, you know, fond memories of my childhood.
Access to knowledge was there, so that's developed, we had.
You know, every aspect of technology, I had to wait for a while. I've obviously spoken before about how long it took for us to get a phone,
about five years, but it's not the only thing. - A telephone? - There was a five-year waiting list,
and we got a rotary telephone, but it dramatically changed our lives.
You know, people would come to our house to make calls to their loved ones. You know, I would have to go all the way to the hospital
to get blood test records, and it would take two hours to go, and they would say, "Sorry, it's not ready. Come back the next day."
Two hours to come back. And that became a five-minute thing. So as a kid, like,
I mean, this light bulb went in my head, you know, this power of technology to kind of change people's lives.
We had no running water, you know, it was a massive drought. So they would get water in these trucks,
maybe eight buckets per household. So me and my brother, sometimes my mom, we would wait in line,
get that and bring it back home. Many years later, like,
we had running water, and we had a water heater, and you could get hot water to take a shower.
I mean, like, so, you know, for me, everything was discrete like that. And so I've always had this thing,
you know, first-time feeling of how technology can dramatically change like, your life,
and the opportunity it brings. So, you know, that was kind of a subliminal takeaway for me
throughout growing up. And, you know, I kind of actually observed it and felt it. You know, so we had to convince my dad for a long time
to get a VCR. Do you know what a VCR is, yeah? (Lex laughing) I'm trying to date you now.
- [Lex] Yeah. - But, you know, because before that, you only had like kind of one TV channel.
Right? That's it. And so, you know, you can watch movies or something like that,
but this was by the time I was in 12th grade, we got a VCR, you know, it was like a Panasonic,
which we had to go to some like shop which had kind of smuggled it in, I guess, and that's where we bought a VCR.
But then being able to record, like a World Cup football game,
or like get bootlegged videotapes and watch movies, like all that.
So like, you know, I had these discrete memories growing up. And so, you know, always left me with the feeling of like,
how getting access to technology drives that step change in your life. - I don't think you'll ever be able to equal
the first time you get hot water. - To have that convenience of going and opening a tap,
and have hot water come out? Yeah. - It's interesting. We take for granted the progress we've made.
If you look at human history, just those plots that look at GDP across 2,000 years,
and you see that exponential growth, to where most of the progress happened since the industrial revolution,
and we just take for granted, we forget how far we've gone. So our ability to understand how great we have it,
and also how quickly technology can improve, is quite poor. - Oh, I mean, it's extraordinary.
You know, I go back to India now, the power of mobile, you know, it's mind-blowing to see the progress
through the arc of time. It's phenomenal. - What advice would you give to young folks listening to this all over the world
who look up to you and find your story inspiring? Who want to be maybe the next Sundar Pichai,
who wanna start, create companies, build something that has a lot of impact in the world?
- Look, you have a lot of luck along the way, but you obviously have to make smart choices, you're thinking about what you want to do,
your brain is telling you something. But when you do things, I think it's important to kind of get that,
listen to your heart, and see whether you actually enjoy doing it. Right, that feeling of, if you love what you do,
it's so much easier, and you're going to see the best version of yourself.
It's easier said than done. I think it's tough to find things you love doing,
but I think kind of listening to your heart a bit more than your mind in terms of figuring out what you want to do
I think is one of the best things I would tell people. The second thing is,
I mean, trying to work with people who you feel, at various points in my life
I worked with people who I felt were better than me, that kind of like, you know, you almost are sitting in a room talking to someone,
and they're like, wow. Like, you know, and you want that feeling a few times, trying to get yourself in a position
where you're working with people who you feel are kind of like stretching your abilities
is what helps you grow, I think. So putting yourself in uncomfortable situations.
And I think, often, you'll surprise yourself. So I think being open-minded enough to kind of put yourself in those positions
is maybe another thing I would say. - What lessons can we learn, maybe from an outsider perspective,
for me, looking at your story and gotten to know you a bit, you're humble, you're kind.
Usually when I think of somebody who has had a journey like yours and climbs to the very top
of leadership in a cut throat world, they're usually gonna be a bit of an asshole.
So what wisdom are we supposed to draw from the fact that your general approach is of balance, of humility,
of kindness, listening to everybody? What's your secret? - I do get angry. I do get frustrated.
I have the same emotions all of us do, right, in the context of work and everything.
But a few things, right? I think, you know, over time I figured out the best way
to get the most out of people. You know, you kind of find mission-oriented people
who are in the shared journey, who have this inner drive to excellence, to do the best.
And, you know, you kind of motivate people, and you can achieve a lot that way, right?
And so it often tends to work out that way. But have there been times like, you know, I lose it?
Yeah. But, you know, maybe less often than others. And maybe over the years,
less and less so, because, you know, I find it's not needed to achieve what you need to do.
- [Lex] So losing your shit has not been productive. - [Sundar] Yeah, less often than not, I think people respond to that,
they may do stuff to react to that. Like, but you actually want them to do the right thing, and so, you know, maybe there's a bit of like sports,
you know, I'm a sports fan, in football coaches, in soccer, that football,
(Lex chuckling) you know, people often talk about like man management, right, great coaches do, right?
I think there is an element of that in our lives. How do you get the best out of the people you work with?
You know, at times you're working with people who are so committed to achieving, if they've done something wrong,
they feel it more than you do, right? So you treat them differently than,
you know, occasionally there are people who you need to clearly let them know, like, "That wasn't okay," or whatever it is.
But I've often found that not to be the case. - And sometimes the right words at the right time,
spoken firmly, can reverberate through time. - Also, sometimes the unspoken words.
You know, people can sometimes see that like, you know, you're unhappy without you saying it.
And so sometimes the silence can deliver that message even more. - Sometimes less is more.
Who's the greatest soccer player of all time? Messi or Ronaldo, or Pele, or Maradona?
- I'm gonna make, you know, in this question- - Is this gonna be a political answer? (laughs) - No, no. I will tell the truthful answer.
- So it's Messi. Okay. - It is. You know, it's been interesting, 'cause my son is a big Cristiano Ronaldo fan,
and so we've had to watch El Classicos together, you know, with that dynamic in there.
I so admire CR7's, I mean, I've never seen an athlete more committed to that kind of excellence,
and so he's one of the all time greats. But you know, for me, Messi is it.
- Yeah, when I see Lionel Messi, you just are in awe that humans are able to achieve that level of greatness
and genius and artistry. When we talk, we'll talk about AI, maybe robotics and this kind of stuff.
That level of genius, I'm not sure you can possibly match by AI in a long time.
It's just an example of greatness, and you have that kind of greatness in other disciplines, but in sport, you get to visually see it,
unlike anything else. And just the timing, the movement,
there's just genius. - Had the chance to see him a couple weeks ago, he played in San Jose, so against the Quakes,
so I went to see it, see the game. Was a fan on the, had good seats,
knew where he would play in the second half, hopefully. And even at his age, just watching him when he gets the ball, that movement,
you know, you're right, that special quality, it's tough to describe, but you feel it when you see it.
Yeah. - He's still got it. If we rank all the technological innovations
throughout human history, let's go back, maybe the history of human civilizations, 12,000 years ago,
and you rank them by how much of a productivity multiplier they've been.
So we can go to electricity, or the labor mechanization of the industrial revolution,
or we can go back to the first agricultural revolution 12,000 years ago. In that long list of inventions, do you think AI,
when history is written 1,000 years from now, do you think it has a chance to be the number one productivity multiplier?
- It's a great question. Look, many years ago, I think it might have been 2017 or 2018, you know, I said at the time,
like, you know, AI is the most profound technology humanity will ever work on, it'll be more profound than fire or electricity.
So I have to back myself, you know, I still think that's the case. You know, when you asked this question,
I was thinking, well, do we have a recency bias? Right, you know, like in sports, it's very tempting to call the current person you're seeing
the greatest player, right? And so is there a recency bias?
And, you know, I do think, from first principles, I would argue
AI will be bigger than all of those. I didn't live through those moments, you know, two years ago I had to go through a surgery,
and then I processed that there was a point in time people didn't have anesthesia when they went through these procedures.
At that moment, I was like, that has got to be the greatest invention (Lex laughing) humanity ever done, right?
So look, we don't know what it is to have lived through those times.
But, you know, many of what you're talking about were kind of these general things
which pretty much affected everything, you know, electricity, or internet, et cetera.
But I don't think we've ever dealt with the technology, both which is progressing so fast, becoming so capable,
it's not clear what the ceiling is. And the main unique,
it's recursively self-improving, right? It's capable of that. And so the fact it is going,
it's the first technology will kind of dramatically accelerate creation itself,
like creating things, building new things, can improve and achieve things on its own,
right, I think like puts it in a different league, right? Different league.
And so I think the impact it will end up having will far surpass everything we've seen before.
Obviously with that comes a lot of important things to think and wrestle with, but I definitely think that'll end up being the case.
- Especially if it gets to the point of where we can achieve superhuman performance on the AI research itself.
So it's the technology that may, it's an open question, but it may be able to achieve a level
to where the technology itself can create itself better than it could yesterday.
- It's like the move 37 of Alpha research, or whatever it is, right? Like, you know, yeah, you're right,
when it can do novel, self-directed research. Obviously for a long time,
we'll have, hopefully always, humans in the loop and all that stuff. And these are complex questions to talk about.
But yes, I think the underlying technology, you know, I've said this, like if you've seen Alpha Go
start from scratch, be clueless, and like become better through the course of a day,
you know, kind of like really it hits you when you see that happen.
Even like, the Veo 3 models, if you sample the models when they were like 30% done and 60% done
and looked at what they were generating, and you kind of see how it all comes together,
it's kind of like, I would say, it's kind of inspiring, a little bit unsettling,
right, as a human. So all of that is true, I think. - Well, the interesting thing
of the industrial revolution, electricity, like you mentioned, you can go back to, again, the agriculture,
the first agricultural revolution, there's what's called the neolithic package
over the first agricultural revolution. That it wasn't just that the nomads settled down
and started planting food, but all this other kinds of technology was born from that,
and it's included this package. It wasn't one piece of technology, it's there's these ripple effects, second and third order effects that happen.
Everything from something silly, like, silly? Profound, like pottery, it can store liquids and food,
to something we kind of take for granted, but social hierarchies,
and political hierarchies, so like early government was formed. Because it turns out if humans stop moving
and have some surplus food, they start coming up with, they get bored (chuckles) and they start coming up with interesting systems.
And then trade emerges, which turns out to be a really profound thing. And like I said, government.
I mean, there's just second and third order effects from that, included in that package, it's incredible.
And probably extremely difficult, if you ask one of the people in the nomadic tribes
to predict that, it would be impossible, and it's difficult to predict. But all that said, what do you think are some of the early things we might see
in the quote-unquote AI package? - I mean, most of it probably we don't know today,
but like, you know, the one thing which we can tangibly start seeing now is,
you know, obviously with the coding progress, you got a sense of it. It's gonna be so easy to imagine,
like thoughts in your head, translating that into things that exist, that'll be part of the package, right?
Like it's gonna empower almost all of humanity to kind of express themselves.
Maybe in the past you could have expressed with words, but like, you could kind of build things into existence.
Right? (laughs) You know, maybe not fully today, we're at the early stages of vibe coding.
You know, I've been amazed at what people have put out online with Veo 3. But it takes a bit of work, right, you have to stitch together a set of prompts.
But all this is gonna get better. The thing I always think about, this is the worst it'll ever be, right,
like at any given moment in time. - Yeah, it's interesting you went there as kind of a first thought.
So an exponential increase of access to creativity.
- Software creation. Are you creating a program? A piece of content to be shared with others?
Games, down the line. All of that like just becomes infinitely more possible.
- Well, I think the big thing is that it makes it accessible. It unlocks the cognitive capabilities
of the entire 8 billion. - No, I agree. Look, think about 40 years ago,
maybe in the U.S. there were five people who could do what you were doing. Like go do a interview.
And you know, but today, think about with YouTube, and other products, et cetera,
like how many more people are doing it. So I think this is what technology does, right?
Like when the internet created blogs, you know, you heard from so many more people.
But with the AI, I think that number won't be in the few hundreds of thousands,
it'll be tens of millions of people, maybe even a billion people, like putting out things into the world in a deeper way.
- And I think it'll change the landscape of creativity. And it makes a lot of people nervous, like for example, whatever,
Fox, MSNBC, CNN are really nervous about this pod. Like, "You mean this dude in a suit could just do this?
And YouTube, and thousands of others, tens of thousands, millions of other creators
can do the same kind of thing?" That makes them nervous. And now you get a podcast from Notebook LM,
that's about 5 to 10 times better than any podcast I've ever done. (Lex laughing) - Not true. But yeah. - I'm joking at this time, but maybe not,
and that changes, you have to evolve. Because on the podcasting front, I'm a fan of podcasts
much more than I am a fan of being a host or whatever. If there's great podcasts that are both AIs,
I'll just stop doing this podcast, I'll listen to that podcast. But you have to evolve, and you have to change, and that makes people really nervous, I think.
But it's also a really exciting future. - The one thing I may say is, I do think, like, in a world in which there are two AI,
I think people value and choose, just like in chess,
you and I would never watch Stockfish 10 or whatever and Alpha Go play against each other, like it would be boring for us to watch.
But Magnus Carlsen and Gukesh, that game would be much more fascinating to watch. So it's tough to say,
like, one way to say is, you'll have a lot more content, and so you will be listening to AI-generated content,
because sometimes it's efficient, et cetera, but the premium experiences you value
might be a version of like, the human essence wherever it comes through. Going back to what we talked earlier
about watching Messi dribble the ball. I know one day, I'm sure a machine will dribble much better than Messi,
but I don't know whether it would evoke that same emotion in us. So I think that'll be fascinating to see.
- I think the element of podcasting or audio books
that is about information gathering, that part might be removed,
or that might be more efficiently, and in a compelling way, done by AI. But then you'll be just nice
to hear humans struggle with the information, (laughs) contend with the information, try to internalize it,
combine it with the complexity of our own emotions, and consciousness, and all that kind of stuff. But if you actually wanna find out
about a piece of history, you go to Gemini. If you want to see Lex struggle with that history,
or other humans, you look at that. But the point is, it's going to change the nature,
continue to change the nature of how we discover information, how we consume the information, how we create that information,
the same way that YouTube changed everything completely, changed news. And that's something our society's struggling with.
- Yeah, YouTube, look, YouTube enabled, I mean, you know this better than anyone else, it's enabled so many creators.
There is no doubt in me that like, we will enable more filmmakers than there have ever been.
Right? You're gonna empower a lot more people. So I think there is an expansionary aspect of this,
which is underestimated, I think. I think it'll unleash human creativity in a way that hasn't been seen before,
it's tough to internalize. The only way is if you brought someone from the '50s or '40s
and just put them in front of YouTube, (laughs) you know, I think it would blow their mind away. Similarly, I think we would get blown away
by what's possible in a 10- to 20-year timeframe. - Do you think there's a future, and how many years out is it that,
let's say, let's put a mark on it, 50% of content, good content, 50% of good content
is generated by Veo 4, 5, 6? - You know, I think depends on what it is for.
Like, you know, maybe if you look at movies today with CGI, there are great filmmakers,
like you still look at like who the directors are and who use it, there are filmmakers who don't use it at all,
you value that. There are people who use it incredibly, you know, think about somebody like a James Cameron,
like what he would do with these tools in his hands. But I think there'll be a lot more content created.
Just like writers today use Google Docs, and not think about the fact that they're using a tool like that.
Like people will be using the future versions of these things, like, it won't be a big deal at all to them.
- I've gotten a chance to get to know Darren Aronofsky well, he's been really leaning in and trying to figure out.
It's fun to watch a genius who came up before any of this was even remotely possible,
he created "Pi," one of my favorite movies, and from there just continued to create a really interesting variety of movies.
And now he's trying to see how can AI be used to create compelling films.
You have people like that. You have people, I've gotten just to know edgier folks that are AI first,
like Dor Brothers, both Aronofski and Dor Brothers create at the edge of the Overton Window of society.
You know, they push, whether it's sexuality or violence.
It's edgy, like artists are, but it's still classy, it doesn't cross that line.
Whatever that line is. You know, Hunter S. Thompson has this line, that the only way to find out where the edge,
where the line is, is by crossing it. And I think for artists, that's true, that's kind of their purpose sometimes,
comedians and artists just cross that line. I wonder if you can comment on the weird place that puts Google.
(Lex chuckling softly) Because Google's line is probably different than some of these artists.
How do you think about, specifically Veo and Flow,
about like how to allow artists to do crazy shit? But also like the responsibility for it not to be too crazy?
- I mean, it's a great question. Look, part of, you mentioned Darren, you know, he's a clear visionary, right?
Part of the reason we started working with him early on Veo is he is one of those people
who's able to kind of see that future, get inspired by it, and kind of showing the way for how creative people
can express themselves with it. Look, I think when it comes to allowing artistic free expression,
it is one of the most important values in a society, right? I think. You know, artists have always been the ones to push,
push boundaries, expand the frontiers of thought. And so, look,
I think that's gonna be an important value we have. So I think we will provide tools,
and put it in the hands of artists for them to use and put out their work.
Those APIs, I mean, I almost think of that as infrastructure. Just like when you provide electricity
to people or something, you want them to use it, and like, you're not thinking about the use cases on top of it. So-
- [Lex] It's a paint brush. - Yeah. And so I think that's how. Obviously, there have to be some things,
and, you know, society needs to decide, at a fundamental level, what's okay, what's not.
We'll be responsible with it. But I do think, you know, when it comes to artistic free expression,
I think that's one of those values we should work hard to defend. - I wonder if you can comment on,
maybe earlier versions of Gemini were a little bit careful on the kind of things you would be willing to answer.
I just wanna comment on, I was really surprised, and pleasantly surprised, and enjoyed the fact that Gemini 2.5 Pro
is a lot less careful in a good sense. Don't ask me why, but I've been doing a lot of research on Genghis Khan,
(Sundar laughing) and the Aztecs, so there's a lot of violence there in that history,
it's a very violent history. I've also been doing a lot of research on World War I and World War II,
and earlier versions of Gemini were very, basically this kind of sense, "Are you sure you wanna learn about this?"
And now it's actually very factual, objective, talks about very difficult parts of human history,
and does so with nuance and depth. It's been really nice. But there's a line there that I guess Google has to kind of walk.
And it's also an engineering challenge, how to do that at scale across all the weird queries (laughs)
that people ask. Can you just speak to that challenge? How do you allow Gemini to say,
again, pardon my French, crazy shit, but not too crazy?
I think one of the good insights here has been, as the models are getting more capable,
the models are really good at this stuff, right, and so I think in some ways, maybe a year ago the models weren't fully there,
so they would also do stupid things more often. And so, you know, you're trying to handle those edge cases,
but then you make a mistake in how you handle those edge cases, and it compounds. But I think with 2.5, what we particularly found is,
once the models cross a certain level of intelligence and sophistication,
you know, they are able to reason through these nuanced issues pretty well. And I think users really want that, right?
Like, you know, you want as much access to the raw model as possible, right?
But I think it's a great area to think about, like, you know, over time, we should allow more and more closer access to it.
Obviously let people custom prompts if they wanted to, and, you know, experiment with it, et cetera.
I think that's an important direction. But look, the first principles we wanna think about it is,
you know, from a scientific standpoint, like making sure the models, and I'm saying scientific
in the sense of like how you would approach math or physics or something like that, from first principles,
having the models reason about the world, be nuanced, et cetera,
you know, from the ground up is the right way to build these things, right? Not like some subset of humans
kind of hard coding things on top of it. So I think it's the direction we've been taking,
and I think you'll see us continue to push in that direction. - Yeah, I actually asked, I gave these notes, I took extensive notes,
and I gave them to Gemini, (chuckles) and said, "Can you ask a novel question that's not in these notes?"
And it wrote, Gemini continues to really surprise me, really surprised me,
it's been really beautiful, it's an incredible model. The question it generated was,
"You," meaning Sundar, "Told the world Gemini's churning out 480 trillion tokens a month,
what's the most life changing five-word sentence hiding in that haystack?" (Sundar laughing) That's a Gemini question.
But it gave me a sense, I don't think you can answer that, but it woke me up to like,
all of these tokens are providing little aha moments for people across the globe.
So that's like learning. Those tokens, people are curious, they ask a question,
and they find something out, and it truly could be life changing. - Oh, it is. Look, you know,
I had the same feeling about Search many, many years ago. You definitely,
you know, the tokens per month has like grown 50 times in the last 12 months. - Is that accurate by the way? - Yeah, it is.
It is accurate. I'm glad it got it right. But you know, that number was 9.7 trillion tokens per month
12 months ago, right? It's gone up to 480, you know, it's a 50x increase.
So there's no limit to human curiosity. And I think it's one of those moments.
Maybe, I don't think it is there today, but maybe one day there's a five-word phrase
which says what the actual universe is, or something like that, and something very meaningful. But I don't think we are quite there yet.
- Do you think the scaling laws are holding strong, there's a lot of ways to describe the scaling laws for AI,
but on the pre-training, on the post-training fronts? So the flip side of that,
do you anticipate AI progress will hit a wall? Is there a wall? - You know, it's a cherished micro kitchen conversation
once in a while I have it, (Lex laughing) but you know, like when Demis is visiting, or you know, Demis, Koray, Jeff, Noam, Sergey,
a bunch of our people, like, you know, we sit and talk about this, right? And look, we see a lot of headroom ahead, right?
I think we've been able to optimize and improve on all fronts, right,
pre-training, post-training, test time compute, tool use,
right, over time, making these more agentic. So getting these models to be more general world models
in that direction, like Veo 3, the physics understanding is dramatically better than what Veo 1 or something like that was.
So you kind of see on all those dimensions, I feel, you know, progress is very obvious to see.
And I feel like there is significant headroom.
More importantly, you know, I'm fortunate to work with some of the best researchers on the planet, right?
They think there is more headroom to be had here, and so I think we have an exciting trajectory ahead.
It's tougher to say, you know, each year I sit and say, "Okay, we are gonna throw 10x more compute
over the course of next year, and like, will we see progress?" Sitting here today,
I feel like the year ahead will have a lot of progress. - And do you feel any limitations like that,
or the bottlenecks, compute-limited, data-limited, idea-limited,
do you feel any of those limitations, or is it full steam ahead on all fronts? - I think it's compute-limited in this sense, right,
like, you know, part of the reason you've seen us do Flash, Nano, Flash, and Pro models,
but not an Ultra model, it's like for each generation, we feel like we've been able to get the Pro model at like,
I don't know, 80, 90% of Ultra's capability, but Ultra would be a lot more,
like slow, and a lot more expensive to serve. But what we've been able to do
is to go to the next generation and make the next generation's Pro as good as the previous generation's Ultra.
- Yeah. - But be able to serve it in a way that it's fast, and you can use it and so on. So I do think scaling laws are working,
but it's tough to get, at any given time,
the models we all use the most is maybe like a few months behind the maximum capability
we can deliver, right? Because that won't be the fastest, easiest to use, et cetera.
- Also that's in terms of intelligence, it becomes harder and harder to measure performance, in quotes.
Because, you know, you could argue Gemini Flash is much more impactful than Pro,
just because of the latency. It's super intelligent already. I mean, sometimes like latency is maybe more important
than intelligence, (laughs) especially when the intelligence is just a little bit less in Flash,
it's still an incredibly smart model. - [Sundar] Yeah. - And so you have to now start measuring impact. And then it feels like benchmarks are less and less capable
of capturing the intelligence of models, the effectiveness of models, the usefulness, the real world usefulness of models.
Another kitchen question. So, lots of folks are talking about timelines for AGI,
or ASI, Artificial Super Intelligence. So AGI, loosely defined,
is basically human expert level at a lot of the main fields of pursuit for humans.
And ASI is what AGI becomes, presumably quickly,
by being able to self-improve. So becoming far superior in intelligence across all disciplines than humans.
When do you think we'll have AGI, is 2030 a possibility? - There's one other term we should throw in there,
I dunno who used it first, maybe Karpathy did, AJI. Have you have you heard AJI,
the Artificial Jagged Intelligence? Sometimes feels that way, right, both there are progress and you see what they can do,
and then like you can trivially find they make numerical errors, or like, you know, counting Rs in strawberry
or something which seems to trip up most models, or whatever it is, right? So maybe we should throw that term in there,
I feel like we are in the AJI phase, where like, dramatic progress, some things don't work well,
but overall, you know, you're seeing lots of progress. But if your question is, will it happen by 2030?
Look, we constantly move the line of what it means to be AGI.
There are moments today, you know, like sitting in a Waymo in a San Francisco street, with all the crowds and the people,
and kind of work its way through, I see glimpses of it there.
The car is sometimes kind of impatient trying to work its way using Astra. Like in Gemini Live,
we're seeing, you know, asking questions about the world. - [User] What's this skinny building doing in my neighborhood?
- [Gemini] It's a streetlight, not a building. - You see glimpses. That's why I use the word AJI,
because then you see stuff which, obviously, you know, we are far from AGI too,
so you have both experiences simultaneously happening to you. I'll answer your question, but I'll also throw out this,
I almost feel the term doesn't matter. What I know is, by 2030, there'll be such dramatic progress.
We'll be dealing with the consequences of that progress, both the positives,
both the positive externalities and the negative externalities that come with it in a big way by 2030.
So that, I strongly feel. Right, whatever we may be arguing about the term, or maybe Gemini can answer
what that moment is in time in 2030, but I think the progress will be dramatic, right?
So, that I believe in. Will the AI think it has reached AGI by 2030?
I would say we will just fall short of that timeline, right? So I think it'll take a bit longer. It's amazing, in the early days of Google DeepMind in 2010,
they talked about a 20-year timeframe to achieve AGI, which is kind of fascinating to see.
But, you know, for me, the whole thing, seeing what Google Brain did in 2012,
and when we acquired DeepMind in 2014, right close to where we are sitting in 2012,
you know, Jeff Dean showed the image of the neural networks, could recognize a picture of a cat, right, and identify it,
you know, there's the early versions of Brain, right? And so, you know, we all talked about couple decades.
I don't think we'll quite get there by 2030, so my sense is it's slightly after that.
But I would stress, it doesn't matter, like what that definition is, because you will have mind blowing progress
on many dimensions. Maybe AI can create videos. We have to figure out, as a society,
we need some system by which we all agree that this is AI-generated, and we have to disclose it in a certain way,
because how do you distinguish reality otherwise? - Yeah, there's so many interesting things you said. So first of all, just looking back at this recent,
now feels like distant history, with Google Brain, I mean, that was before TensorFlow, before TensorFlow was made public and open sourced.
So the tooling matters too, combined with GitHub ability to share code. Then you have the ideas of attention transformers,
and the diffusion now, and then there might be a new idea that seems simple in retrospect, but will change everything,
and that could be the post-training, the inference time innovations. And I think Shadcn tweeted that Google is just one great UI
from completely winning the AI race. (chuckles) Meaning like, UI is a huge part of it,
like, how that intelligence, I think Logan Kilpatrick likes to talk about this,
right now it's an LLM, but when is it gonna become a system, where you're talking about shipping systems
versus shipping a particular model? Yeah, that matters too, how the system manifests itself
and how it presents itself to the world, that really, really matters. - Oh, hugely so.
There are simple UI innovations which have changed the world, right? And I absolutely think so.
We will see a lot more progress in the next couple of years, as I think AI, itself,
on a self-improving track for UI itself. Like, you know, today, we are like constraining the models,
the models can't quite express themselves in terms of the UI too to people.
But that is like, you know, if you think about it, we've kind of boxed them in that way,
but given these models can code, you know, they should be able to write the best interfaces
to express their ideas over time, right? - That is an incredible idea.
So their APIs already open, so you can, (chuckles) you create a really nice agentic system
that continuously improves the way you can be talking to an AI.
- Yeah. - But a lot of that is the interface, and then of course the incredible multimodal aspect
of the interface that Google has been pushing. - These models are natively multimodal, they can easily take content from any format,
put it in any format. They can write a good user interface. They probably understand your preferences better over time.
Like, you know? And so all this is like the evolution ahead, right? And so it goes back to where we started the conversation,
like, I think there'll be dramatic evolutions in the years ahead. - Maybe one more kitchen question.
P(doom)
This even further ridiculous concept of p doom. So the philosophically-minded folks in the AI community
think about the probability that AGI, and then ASI, might destroy all of human civilization.
I would say my p doom is about 10%. Do you ever think about this kind of long-term threat of ASI,
and what would your p doom be? - Look, I mean, for sure, look, I've both been very excited about AI,
but I've always felt this is a technology, you know, you have to actively think about the risks
and work very, very hard to harness it in a way that it all works out well.
On the p doom question, look it won't surprise you to say that's probably another micro kitchen conversation
that pops up once in a while, right? And given how powerful the technology is, maybe stepping back,
you know, when you're running a large organization, if you can kind of align the incentives of the organization,
you can achieve pretty much anything, right? Like, you know, if you can get kind of people all marching towards like a goal in a very focused way,
in a mission-driven way, you can pretty much achieve anything. But it's very tough to organize all of humanity that way.
But I think if p doom is actually high, at some point all of humanity is like aligned
in making sure that's not the case, right? And so we'll actually make more progress against it,
I think. So the irony is there is a self-modulating aspect there.
Like I think if humanity collectively puts their mind to solving a problem, whatever it is, I think we can get there.
So because of that, you know, I think I'm optimistic on the p doom scenarios,
I think the underlying risk is actually pretty high, but, you know, I have a lot of faith in humanity
kind of rising up to meet that moment. - That's really, really well put. I mean, as the threat becomes more concrete and real,
humans do really come together and get their shit together. Well, the other thing I think people don't often talk about
is probability of doom without AI. So there's all these other ways
that humans can destroy themselves, and it's very possible, at least I believe so, that AI will help us become smarter,
kinder to each other, more efficient, it'll help more parts of the world flourish
where it would be less resource-constrained, which is often the source of military conflict
and tensions and so on. So we also have to load into that, what's the p doom without AI?
p doom with AI, p doom without AI. 'Cause it's very possible that AI will be the thing that saves us,
saves human civilizations from all the other threats. - I agree with you. I think it's insightful.
Look, I felt like to make progress on some of the toughest problems, would be good to have AI there helping you, right?
And so that resonates with me for sure, yeah. - Quick pause. Bathroom break?
- [Sundar] All right. (laughs) - All right, let's do that. (laughs) If Notebook LM was the same,
like what I saw today with Beam, if it was compelling in the same kind of way?
Blew my mind. It was incredible. I didn't think it's possible. It didn't think- - Can you imagine like,
the U.S. President or the Chinese President being able to do something like Beam, with the live meet translation working well?
So they're both sitting and talking, make progress a bit more? (chuckles)
- Yeah, just for people listening, took a quick bathroom break, and now we're talking about the demo I did.
We'll probably post it somewhere, somehow, maybe here. I got a chance to experience Beam,
and it was, it's hard to describe it in words how real it felt
with just, what is it, six cameras? It's incredible. It's incredible. - It's one of the toughest products of,
you can't quite describe it to people, even when we show it in slides, et cetera, like you don't know what it is.
You have to kind of experience it. - On the world leaders front, on politics, geopolitics,
there's something really special, again, with studying World War II, and how much could have been saved
if Chamberlain met Stalin in-person. And I sometimes also struggle explaining to people,
articulating why I believe meeting in-person for world leaders is powerful.
It just seems naive to say that, but there is something there in-person. And with Beam, I felt that same thing,
and then I'm unable to explain, all I kept doing is what like a child does.
You look real. (laughs) You know? And, I mean, I don't know if that makes meetings
more productive or so on, but it certainly makes them more,
the same reason you wanna show up to work versus remote sometimes, that human connection.
I don't know what that is, it's hard to put into words.
There's something beautiful about great teams collaborating on a thing that's not captured by the productivity of that team,
or by whatever on paper. Some of the most beautiful moments you experience in life is at work.
Pursuing a difficult thing together for many months? - Oh. - [Lex] There's nothing like it.
- You're in the trenches, and you do form bonds that way. - For sure. And to be able to do that,
like somewhat a remotely, and that same personal touch? I don't know, that's a deeply fulfilling thing. I know a lot of people, I personally hate meetings,
because a significant of meetings, when done poorly,
don't serve a clear purpose. But that's a meeting problem, that's not a communication problem.
If you could improve the communication for the meetings that are useful, that's just incredible. So yeah,
I was blown away by the great engineering behind it, and then we get to see what impact that has.
That's really interesting, but just incredible engineering, really impressive. - No, it is. And obviously we'll work hard over the years
to make it more and more accessible. But yeah, even on a personal front outside of work meetings,
you know, a grandmother who's far away from her grandchild, and being able to, you know,
have that kind of an interaction, right, all that I think will end up being very meaningful.
Nothing substitutes being in-person, but, you know, it's not always possible, you could be a soldier deployed,
trying to talk to your loved ones. You know?
So that's what inspires us. - When you and I hung out last year and took a walk,
Toughest leadership decisions
I remember, I don't think we talked about this, (chuckles) but I remember, you know, outside of that,
seeing dozens of articles written by analysts and experts and so on, that Sundar Pichai should step down.
Because the perception was that Google was definitively losing the AI race,
has lost its magic touch in the rapidly-evolving technological landscape.
And now a year later, it's crazy, you showed this plot of all the things that were shipped
over the past year. It's incredible. And Gemini Pro is winning across many benchmarks and products as we sit here today.
So take me through that experience, when there's all these articles saying, "You're the wrong guy to lead Google through this,
Google's lost, it's done, it's over," to today, where Google is winning again.
What were some low points during that time? - Look,
I mean, lots to unpack, you know, obviously, like,
the main bet I made as a CEO was to really make sure the company
was approaching everything in a AI-first way, really, you know, setting ourselves up
to develop AGI responsibly, right, and make sure we are putting out products
which embodies that, things that are very, very useful for people. So look, I knew,
even through moments like that last year, you know, I had a good sense
of what we were building internally, right? So I'd already made, you know, many important decisions,
you know, bringing together teams of the caliber of Brain, and DeepMind, and setting up Google DeepMind.
There were things like, we made the decision to invest in TPUs 10 years ago.
So we knew we were scaling up and building big models. Anytime you're in a situation like that,
a few aspects, I'm good at tuning out noise, right,
separating signal from noise. Do you scuba dive? Like, have you? - No. - No.
You know, it's amazing, like, I'm not good at it, but I've done it a few times. But sometimes you jump in the ocean,
it's so choppy, but you go down one feet under,
it's the calmest thing in the entire universe, right? So there's a version of that, right?
Like, you know, running Google, you know, you may as well be coaching Barcelona
or Rio Madrid, right? - [Lex] Yeah. (laughs) - Like, you know, you have a bad season. So there are aspects to that.
But you know, like, look, I'm good at tuning out the noise. I do watch out for signals,
you know, it's important to separate the signal from the noise, so there are good people sometimes making good points outside,
so you wanna listen to it, you want to take that feedback in. But you know, internally,
like, you know, you are making a set of consequential decisions. Right, as leaders, you're making a lot of decisions.
Many of them are like inconsequential, like it feels like, but over time you learn
that most of the decisions you're making on a day-to-day basis doesn't matter.
Like, you have to make them, and you're making them just to keep things moving. But you have to make a few consequential decisions, right?
And we had set up the right teams, right leaders,
we had world class researchers, we were training Gemini.
Internally, there are factors which were, for example, outside people may not have appreciated, I mean, TPUs are amazing,
but we had to ramp up TPUs too. That took time, right, to scale actually having enough TPUs
to get the compute needed. But I could see, internally, the trajectory we were on,
and, you know, I was so excited internally about the possibility.
To me, this moment felt like one of the biggest opportunities ahead for us as a company.
The opportunity space ahead over the next decade, next 20 years, is bigger than what has happened in the past.
And I thought we were set up, like better than most companies in the world,
to go realize that vision. - I mean, you had to make some consequential, bold decisions,
like you mentioned the merger of DeepMind and Brain.
Maybe it's my perspective, just knowing humans, I'm sure there's a lot of egos involved, it's very difficult to merge teams,
and I'm sure there were some hard decisions to be made. Can you take me through your process of how you think through that,
do you go to pull the trigger and make that decision? Maybe what were some painful points, how do you navigate those turbulent waters?
- Look, we were fortunate to have two world class teams, but you're right, it's like somebody coming and telling to you,
take Stanford and MIT. - [Lex] Right. - And then put them together and create a great department, right? And easier said than done.
But we were fortunate, you know? Phenomenal teams, both had their strengths,
you know, they were run very differently. Right, like Brain was kind of a lot of diverse projects,
bottoms up, and out of it came a lot of important research breakthroughs. DeepMind, at the time,
had a strong vision of how you wanna build AGI, and so they were pursuing their direction.
But I think through those moments, luckily tapping into, you know, Jeff had expressed a desire to be more,
to go back to more of a scientific individual contributor roots. You know, he felt like management
was taking up too much of his time. And Demis, naturally, I think,
you know, was running DeepMind, and was a natural choice there.
But I think it was, you are right, you know, it took us a while to bring the teams together, credit to Demis, Jeff, Koray,
all the great people there, they worked super hard to combine the best of both worlds,
when you set up that team. A few sleepless nights here and there, as we put that thing together.
We were patient in how we did it so that it works well for the long term, right?
And some of that in that moment, I think, yes, with things moving fast,
I think you definitely felt the pressure, but I think we pulled off that transition well,
and, you know, I think they're obviously doing incredible work,
and there's a lot more incredible things ahead coming from them. - Like we talked about, you have a very calm, even-tempered, respectful demeanor.
During that time, whether it's the merger, or just dealing with the noise,
were there times where frustration boiled over? Like, did you have to go a bit more intense on everybody
than you usually would? - Probably, you know? Probably. I think in the sense that,
you know, there was a moment where we were all driving hard, but when you're in the trenches, working with passion,
you're gonna have days, right, you disagree, you argue. But like all that,
I mean, just par of the course of working intensely, right? And, you know, at the end of the day,
all of us are doing what we are doing because the impact it can have, we are motivated by it,
it's like, you know, for many of us, this has been a long-term journey,
and so it's been super exciting. The positive moments far outweigh the kind of stressful moments.
Just early this year, I had a chance to celebrate back to back over two days,
like, you know, Nobel Prize for Geoff Hinton, and the next day, a Nobel Prize for Demis and John Jumper.
You know, you worked with people like that, all that is super inspiring. - Is there something like with you, where you had to like, put your foot down
maybe with less, versus more, or like, "I'm the CEO, and we're doing this."
- To my earlier point about consequential decisions you make, there are decisions you make people can disagree pretty vehemently.
But at some point, like, you know, you make a clear decision, and you just ask people to commit, right?
Like, you know, you can disagree, but it's time to disagree and commit so that we can get moving.
And whether it's put putting the foot down, or, you know, it's a natural part of what all of us have to do.
And, you know, I think you can do that calmly, and be very firm in the direction you are making the decision.
And I think if you're clear, actually people over time respect that, right? Like, you know, if you can make decisions with clarity.
I find it very effective in meetings where you're making such decisions
to hear everyone out. I think it's important, when you can, to hear everyone out.
Sometimes what you're hearing actually influences how you think about it, and you're wrestling with it, and making a decision.
Sometimes you have a clear conviction, and you state so, "Look, this is how I feel,
and this is my conviction." And you kind of place the bet, and you move on. - Are there big decisions like that?
I kind of intuitively assumed the merger was the big one. - I think that was a very important decision,
you know, for the company. To meet the moment, I think we had to make sure we were doing that
and doing that well. I think that was a consequential decision. There were many other things. We set up a AI infrastructure team,
like, to really go meet the moment, to scale up the compute we needed to, and really brought teams
from disparate parts of the company, kind of created it to move forward.
You know, bringing people, like getting people to kind of work together physically, both in London, with DeepMind,
and what we call Gradient Canopy, which is where the Mountain View Google DeepMind teams are.
But one of my favorite moments is, I routinely walk, multiple times per week,
to the Gradient Canopy building, where our top researchers are working on the models.
Sergey is often there amongst them, right? (Lex laughing) Like, you know, just looking at,
getting an update on the model, seeing loss curves. So, all that, I think that cultural part of getting the teams together back with that energy
I think ended up playing a big role too. - What about the decision to recently add AI Mode?
AI mode vs Google Search
So Google Search is, as they say, the front page of the internet,
it's like a legendary, minimalist thing with 10 blue links.
Like, when people think internet, they think that page, and now you're starting to mess with that.
So the AI Mode, which is a separate tab, and then integrating AI in the results. I'm sure there were some battles
in meetings on that one. (chuckles softly) - Look, in some ways when mobile came,
you know, people wanted answers to more questions, so we're kind of constantly evolving it.
But you're right this moment, you know, that evolution, because the underlying technology is becoming much more capable.
You know, you can have AI give a lot of context. You know? But one of our important design goals though,
is when you come to Google Search, you are going to get a lot of context,
but you're gonna go and find a lot of things out on the web. So that will be true in AI mode, in AI overviews, and so on.
But I think, to our earlier conversation, we're still giving you access to links, but think of the AI as a layer
which is giving you context, summary. Maybe in AI mode, you can have a dialogue with it
back and forth on your journey, right?
But through it all, you're kind of learning what's out there in the world. So those core principles don't change,
but I think AI Mode allows us to push, we have our best models there, right,
models that are using search as a deep tool, really for every query you're asking,
kind of fanning out, doing multiple searches, like kind of assembling that knowledge
in a way so you can go and consume what you want to, right? And that's how we think about it.
- I got a chance to listen to a bunch of Elizabeth, Liz Reid, describe this. - [Sundar] Yeah. - Two things stood out to me that you mentioned.
One thing is what you were talking about is the query fan out, which I didn't even think about before,
is the powerful aspect of integrating a bunch of stuff on the web for you in one place.
So that, yes, it provides that context so that you can decide which page to then go onto.
The other really, really big thing speaks to the earlier, in terms of productivity multiplier
that we're talking about that you mentioned was language. So one of the things you don't quite understand is,
through AI Mode, for non-English speakers, you make sort of,
let's say English language websites accessible, but in the reasoning process,
as you've tried to figure out what you're looking for, of course, once you show up to a page, you can use a basic translate. - [Sundar] Yeah.
- But that process of figuring it out, if you empathize with a large part of the world
that doesn't speak English, their like, web, is much smaller in that original language.
And so it, again, unlocks that huge cognitive capacity there. You know, you take for granted here,
with all the bloggers and the journalists writing about AI Mode, you forget that this now unlocks,
because Gemini is really good at translation. - No, it is. I mean, the multimodality, the translation,
its ability to reason, we're dramatically improving tool use.
So putting that power in the flow of Search, I think, look, I'm super excited with the AI overviews,
we've seen the product has gotten much better, you know, we measured using all kinds of user metrics.
It's obviously driven strong growth of the product. And, you know, we've been testing AI Mode,
you know, it's now in the hands of millions of people, and the early metrics are very encouraging.
So look, I'm excited about this next chapter of Search. - For people who are not thinking through or aware of this,
so there's the 10 blue links, with the AI overview on top that provides a nice summarization, you can expand it.
- [Sundar] And you have sources and links now embedded. - I believe, at least Liz said so,
I actually didn't notice it, but there's ads in the AI Overview also.
I don't think there's ads in AI Mode. When ads in AI Mode? (chuckles)
So, when do you think, I mean, okay, we should say that, in the '90s,
I remember the animated gifs, banner gifs that take you to some shady websites
that have nothing to do with anything. AdSense revolutionized advertisement, it's one of the greatest inventions in recent history,
because it allows us, for free, to have access to all these kinds of services.
So ads fuel a lot of really powerful services. And, at its best, it's showing you relevant ads,
but also very importantly, in a way that's not super annoying. Right? In a classy way. So when do you think it's possible to add ads into AI Mode?
And what does that look like from a classy, non-annoying perspective? - Two things.
Early part of AI Mode, we'll obviously focus more on the organic experience to make sure we are getting it right.
I think the fundamental value of ads are, it enables access to deploy the services
to billions of people. Second is ads are, the reason we've always taken ads seriously
is we view ads as commercial information, but it's still information, and so we bring the same quality metrics to it.
I think with AI Mode, to our earlier conversation about it, I think AI itself will help us, over time,
figure out the best way to do it. I think, given we are giving context around everything,
I think it'll give us more opportunities to also explain, "Okay, here's some commercial information."
Like, today, as a podcaster, you do it at certain spots, and you probably figure out what's best in your podcast.
So there are aspects of that. But I think, you know, the underlying need
of people value commercial information, businesses are trying to connect to users,
all that doesn't change in an AI moment. But look, we will rethink it.
You've seen us in YouTube now do a mixture of subscription and ads.
Like, obviously, you know, we are now introducing subscription offerings
across everything. And so as part of that, the optimization point will end up being
a different place as well. - Do you see a trajectory in the possible future where AI mode completely replaces the 10 blue links
plus AI overview? - Our current plan is AI Mode is gonna be there as a separate tab
for people who really wanna experience that, but it's not yet at the level where
our main Search pages. But as features work, we'll keep migrating it to the main page.
And so you can view it as a continuum, AI Mode will offer you the bleeding edge experience,
but things that work will keep overflowing to AI overviews in the main experience.
- And the idea that AI Mode will still take you to the web, to the human-created web. - Yes. That's gonna be a core design principle for us.
- So really, if users decide, right, they drive this. - [Sundar] Yeah. - It's just exciting, a little bit scary,
that it might change the internet. Because Google has been dominating with a very specific look
and idea of what it means to have the internet, and as you move to AI mode.
I mean, it's just a different experience. I think Liz was talking about, I think you've mentioned that you ask more questions,
you ask longer questions, - Dramatically different types of questions. - Yeah, like it actually fuels curiosity.
Like, I think for me, I've been asking just a much larger number of questions
of this black box machine, let's say, whatever it is. And with AI overview, it's interesting,
because I still value the human, I still ultimately want to end up on the human-created web,
but, like you said, the context really helps. - It helps us deliver higher quality referrals, right?
You know, where people are like, they have much higher likelihood of finding what they're looking for. They're exploring, they're curious,
their intent is getting satisfied more. So that's what all our metrics show. - It makes the humans that create the web nervous,
the journalists are getting nervous. They've already been nervous. Like we mentioned, CNN is nervous because of podcasts.
It makes people nervous. - Look, I think news and journalism will play an important role,
you know, in the future. We are pretty committed to it, right? And so I think making sure that ecosystem,
in fact, I think we'll be able to differentiate ourselves as a company over time because of our commitment there.
So it's something I think, you know, I definitely value a lot, and as we are designing,
we'll continue prioritizing approaches. - I'm sure for the people who want, they can have a fine-tuned AI model
that's click-bait hit pieces that will replace current journalism.
That's a shot at journalism. Forgive me. But I find that, if you're looking for really strong criticism of things,
that Gemini is very good at providing that. - Oh, absolutely. - It's better than anything, for now,
I mean, people are concerned that there would be bias that's introduced as the AI systems become more and more powerful,
there's incentive from sponsors to roll in and try to control the output of the AI models.
But for now, the objective criticism that's provided is way better than journalism. Of course, the argument is
the journalists are still valuable, but then, I don't know, the crowdsource journalism that we get on the open internet
is also very, very powerful. - I feel like they're all super important things. I think it's good that
you get a lot of crowdsourced information coming in, but I feel like there is real value
for high quality journalism, right? And I think these are all complimentary.
I think like I view it as, I find myself constantly seeking out also,
like try to find objective reporting on things too. And sometimes you get more context
from the crowdfunded sources you read online, but I think both end up playing a super important role.
- So you've spoken a little about this, Demis talked about this, as sort of the slice of the web
that will increasingly become about providing information for agents. So we can think about it as like two layers of the web,
one is for humans, one is for agents. Do you see the AI agents?
Do you see the one that's for AI agents growing over time? Do you see their still being long-term, 5, 10 years,
value for the human-created, human-created for the purpose of human consumption web,
or will it all be agents in the end? - Today, like, not everyone does,
but, you know, you go to a big retail store, you love walking the aisle, you love shopping,
or grocery store, picking out food, et cetera. They're also online shopping, and they're delivering, right?
So both are complimentary, and like, that's true for restaurants, et cetera.
So I do feel like, over time, websites will also get better for humans, they will be better designed,
AI might actually design them better for humans. So I expect the web to get a lot richer,
and more interesting, and better to use. At the same time, I think there'll be an agentic web,
which is also making a lot of progress. And you have to solve the business value,
and the incentives to make that work well, right, like for people to participate in it.
But I think both will coexist, and, obviously, the agents may not need the same,
I mean, may not? They won't need the same design and the UI paradigms which humans need to interact with.
But I think both will be there. - I have to ask you about Chrome.
Google Chrome
I have to say, for me, personally, Google Chrome is probably,
I don't know, I'd like to see where I would rank it, but in this temptation, and this is not a recency bias,
although it might be a little bit, but I think it's up there, top three, maybe the number one piece of software for me
of all time. It's incredible. It's really incredible. The browser is our window to the web,
and Chrome really continues for many years, but even initially to push the innovation on that front
when it was stale, and it continues to challenge, it continues to make it more performant,
so efficient, and just innovate constantly. And the Chromium aspect of it.
Anyway, (chuckles) you were one of the pioneers of Chrome, pushing for it when it was an insane idea,
probably one of the ideas that was criticized and doubted and so on.
So can you tell me the story of what it took to push for Chrome?
What was your vision? - Look, it was such a dynamic time around 2004, 2005,
with AJAX, the web suddenly becoming dynamic in a matter of few months,
Flickr, Gmail, Google Maps all kind of came into existence, right?
Like the fact that you have an interactive, dynamic web, the web was evolving from simple text pages, simple HTML,
to rich, dynamic applications. But at the same time,
you could see the browser was never meant for that world. Right? Like JavaScript execution was super slow.
You know, the browser was far away from being an operating system for that rich modern web which was coming into place.
So that's the opportunity we saw, like, you know, it's an amazing early team.
I still remember the day we got a shell on Webkit running, and how fast it was.
You know, we had the clear vision for building a browser, like we wanted to bring core OS principles into the browser.
Right? Like, so we built a secure browser sandbox,
each tab was its own. These things are common now, but at the time, like it was pretty unique.
We found an amazing team in our Aarhus, Denmark, with a leader who built V8, the JavaScript VM,
which at the time was 25 times faster than any other JavaScript VM out there.
And by the way, you are right, we open sourced it all, and, you know, put it in Chromium too.
But we really thought the web could work much better, you know, much faster,
and you could be much safer browsing the web. And the name Chrome came was because we literally felt people were like,
the chrome of the browser was getting clunkier, we wanted to minimize it.
And so that was the origins of the project. Definitely, obviously, highly biased person here
talking about Chrome. But, you know, it's the most fun I've had building a product from the ground up,
and it was an extraordinary team. My co-founders on the project were terrific,
so, definite fond memories. - So for people who don't know, Sundar, I mean, it's probably fair to say,
you're the reason we have Chrome. Yes, I know there's a lot of incredible engineers, but pushing for it inside a company
that probably was opposing it, because it's a crazy idea, because as everybody probably knows,
it's incredibly difficult to build a browser. - Yeah, look, Eric, who was the CEO at the time, I think it was less that he was opposed to it,
he kind of firsthand knew what a crazy thing it is to go build a browser, and so he definitely was like,
this is, you know, there was a crazy aspect to actually wanting to go build a browser.
But he was very supportive. You know, everyone, the founders,
where I think once we started building something, and we could use it and see how much better,
from then on, like, you know, you're really tinkering with the product and making it better. It came to life pretty fast.
- What wisdom do you draw from that, from pushing through on a crazy idea in the early days
that ends up being revolutionary? For future crazy ideas like it.
- I mean, this is something Larry and Sergey have articulated clearly, I really internalized this early on,
which is, you know, their whole feeling around working on moonshots,
like as a way, when you work on something very ambitious, first of all, it attracts the best people, right?
So that's an advantage you get. Number two, because it's so ambitious, you don't have others working on something crazy,
so you pretty much have the path to yourselves, right? It's like Waymo self-driving. Number three,
even if you end up quite not accomplishing what you set out to do, and you end up doing 60, 80% of it,
it'll end up being a terrific success. So, you know, that's the advice I would give people, right?
I think like, you know, it's just aiming for big ideas has all these advantages,
and it's risky, but it also has all these advantages which people I don't think fully internalize.
- I mean, you mentioned one of the craziest, biggest moonshots, which is Waymo. It's one,
when I first saw, over a decade ago, a Waymo vehicle,
a Google self-driving car vehicle, for me, it was an aha moment for robotics.
It made me fall in love with robotics even more than before, it gave me a glimpse into the future. So it's incredible,
truly grateful for that project, for what it symbolizes. But it's also a crazy moonshot.
For a long time, (laughs) Waymo's been just like you mentioned with scuba diving, just not listening to anybody,
just calmly improving the system better and better, and more testing, just expanding the operational domain more and more.
First of all, congrats on 10 million paid robo taxi rides. What lessons do you take from Waymo
about like, the perseverance, the persistence on that project? - Oh, really proud of the progress we have had with Waymo.
One of the things I think we were very committed to, you know, the final 20% can look like, I mean, we always say, right,
the first 80% is easy, the final 20% takes 80% of the time, I think we are definitely were working through that phase
with Waymo, but I was aware of that. But, you know, we knew we were at that stage.
We knew we were the technology gap between, while there were many people,
many other self-driving companies, we knew the technology gap was there. In fact, right at the moment when others were doubting Waymo
is when, I don't know, I made the decision to invest more in Waymo, right? So in some ways, it's counterintuitive.
But I think, look, we've always been a deep technology company, and like, you know,
Waymo is a version of kind of building a AI robot that works well. And so we get attracted to problems like that,
the caliber of the teams there, you know, phenomenal teams. And so I know you follow the space super closely,
you know, I'm talking to someone who knows the space well, but it was very obvious it's gonna get there,
and you know, there's still more work to do, but it's a good example where we always prioritized
being ambitious, and safety at the same time, right? And equally committed to both, and pushed hard,
and, you know, couldn't be more thrilled with how it's working,
how much people love the experience. And this year has definitely, we've scaled up a lot,
and we'll continue scaling up in '26. - That said, the competition is heating up.
You've been friendly with Elon, even though technically he's a competitor, but you've been friendly with a lot of tech CEOs
in that way, just showing respect towards them and so on, what do you think about the robo taxi efforts that Tesla's doing?
Do you see it as competition, what do you think? Do you like the competition? - We are one of the earliest and biggest backers of SpaceX
as Google, right? So, you know, thrilled with what SpaceX is doing,
and fortunate to be investors as a company there, right? And, look, we don't compete with Tesla directly,
we are not making cars, et cetera, right, we are building L4, 5 autonomy, we are building a Waymo driver,
which is general purpose and can be used in many settings. They're obviously working on making Tesla self-driving too,
I just assume it's a de facto that Elon would succeed in whatever he does. (Lex laughs) So like, you know,
that is not something I question. So but I think we're so far,
these spaces are such vast spaces. Like I think about transportation,
the opportunity space, the Waymo driver is a general purpose technology we can apply in many situations.
So you have a vast, green space. In all future scenarios, I see Tesla doing well,
and, you know, Waymo doing well. - Like we mentioned with the Neolithic package,
I think it's very possible that in the quote-unquote, AI package, when the history is written, autonomous vehicles, self-driving cars
is like the big thing that changes everything. Imagine, over a period of a decade or two,
just a complete transition from manually driven to autonomous in ways we might not predict.
It might change the way we move about the world completely. So, you know, the possibility of that.
And then the second and third order effects, as you're seeing now with Tesla,
very possibly you would see some internally with Alphabet,
maybe Waymo, maybe some of the Gemini Robotics stuff, it might lead you into the other domains of robotics.
Because we should remember Waymo's a robot, it just happens to be on four wheels.
So you said that the next big thing, we can also throw that into AI package,
the big aha moment might be in the space of robotics. What do you think that would look like?
- Demis and the Google DeepMind team is very focused on Gemini Robotics, right? So we are definitely building the underlying models well.
So we have a lot of investments there, and I think we are also pretty cutting edge in our research there.
So we are definitely driving that direction. We obviously are thinking about applications in robotics.
We'll kind of work, seeing as we are partnering with a few companies today,
but it's an area I would say, stay tuned, we are yet to fully articulate our plans outside,
but it's an area we are definitely committed to driving a lot of progress. But I think AI ends up driving
that massive progress in robotics, the field has been held back for a while.
I mean, hardware has made extraordinary progress. The software had been the challenge,
but, you know, with AI now, and the generalized models we are building,
you know, building these models, getting them to work in the real world, in a safe way, in a generalized way
is the frontier we're pushing pretty hard on. - Well, it's really nice to see that the models and the different teams integrated
to where all of them are pushing towards one world model that's being built. So from all these different angles, multimodal,
you're ultimately trying to get, Gemini, the same thing that would make AI Mode
really effective in answering your questions, which requires a kind of world model, is the same kind of thing
that would help a robot be useful in the physical world. So everything's aligned. - That is what makes this moment so unique,
'cause, running a company, for the first time, you can do one investment in a very deep, horizontal way,
on top of which you can drive multiple businesses forward. Right?
And, you know, that's effectively what we are doing in Google and Alphabet, right? - Yeah, it's all coming together
like it was planned ahead of time, but it's not, of course, it's all distributed. I mean, if Gmail, and Sheets,
and all these other incredible services, I can sing Gmail praises for years, I mean, just revolutionized email.
But the moment you start to integrate AI Gemini into Gmail, I mean, that's the other thing,
speaking of productivity multiplier, people complain about email, but that changed everything. Email, like the invention of email, changed everything.
And it's been ripe, there's been a few folks trying to revolutionize email, some of them on top of Gmail,
but that's like ripe for innovation, not just spam filtering, but (chuckles softly)
you demoed a really nice demo of- - Personalized responses, right? - Personalized responses.
And at first I was like, at first I felt really bad about that,
but then I realized that's there's nothing wrong to feel bad about. Because the example you gave is when a friend asks,
you know, you went to whatever hiking location, do you have any advice?
And they just search us through all your information to give them good advice, and then you put the cherry on top, maybe some love or whatever, comradery.
But the informational aspect, the knowledge transfer, it does for you. - I think there'll be important moments.
Like it should be, like today, if you write a card in your own handwriting and send it to someone, that's a special thing.
Similarly, there'll be a time, I mean, to your friends, maybe your friend wrote and said he's not doing well or something,
you know, those are moments you wanna save your times for writing something, reaching out.
But you know, like saying, "Give me all the details of the trip you took," you know, to me,
makes a lot of sense for a AI assistant to help you, right? And so I think both are important,
but I think I'm excited about that direction. - Yeah, I think, ultimately, it gives more time for us humans
to do the things we humans find meaningful. And I think it scares a lot of people, because we're gonna have to ask ourselves the hard question,
of like, what do we find meaningful? And I'm sure there's answers, and it's the old question of the meaning of existence,
is you have to try to figure that out. That might be, ultimately, parenting,
or being creative in some domains of art, or writing. And it challenges. Like, you know, it's a good question to ask yourself,
like, in my life, what is the thing that brings me most joy and fulfillment?
And if I'm able to actually focus more time on that, that's really powerful. - I think that's the holy grail.
If you get this right, I think it allows more people to find that. - I have to ask you, on the programming front,
Programming
AI is getting really good at programming. Gemini, both the agentic and just the LLM has been incredible.
So a lot of programmers are really worried that their jobs, they will lose their jobs.
How worried should they be, and how should they adjust so they can be thriving in this new world
where more and more code is written by AI? - I think a few things. Looking at Google,
you know, we've given various stats around like, you know, 30% of code now uses like AI generated suggestions
or whatever it is. But the most important metric, and we carefully measure it, is like, how much has our engineering velocity increased
as a company due to AI, right? And it's like tough to measure, and we can rigorously try to measure it.
And our estimates are at that number is now at 10%, right? Like now, across the company,
we've accomplished a 10% engineering velocity increase
using AI. But we plan to hire more engineers next year, right?
So because the opportunity space of what we can do
is expanding too, right? And so I think, hopefully,
you know, for at least in the near to midterm, for many engineers,
it frees up more and more of the, you know, even in engineering and coding,
there are aspects which are so much fun, you're designing, you're architecting, you're solving a problem,
there's a lot of grant work, you know, which all goes hand in hand, but it hopefully takes a lot of that away,
makes it even more fun to code, frees you up more time to create, problem solve,
brainstorm with your fellow colleagues and so on, right? So that's the opportunity there.
And second, I think like, you know, it'll attract, it'll put the creative power in more people's hands,
which means people will create more, that means there'll be more engineers doing more things.
So it's tough to fully predict. But you know, I think in general, in this moment,
it feels like, you know, people adopt these tools and be better programmers.
Like there are more people playing chess now than ever before, right? (chuckles) So, you know, it feels positive that way to me,
at least speaking from within a Google context, is how I would, you know, talk to them about it.
- I still, I just know anecdotally, a lot of great programmers are generating a lot of code.
So their productivity, they're not always using all the code, just, you know, there's still a lot of editing,
but like, even for me, I'm still programming as a side thing,
I think I'm like 5x more productive. I think even for a large code base
that's touching a lot of users, like Google's does, I'm imagining like, very soon,
that productivity should be going up even more. - The big unlock will be as we make the agentic capabilities
much more robust, right? I think that's what unlocks that next big wave. I think the 10% is like a massive number.
Like, you know, if tomorrow, like I showed up and said like, you can improve a large organization's productivity by 10%,
when you have tens of thousands of engineers, that's a phenomenal number. And, you know,
that's different than what other site statistics are saying, like, you know, "This percentage of code is now written by AI."
I'm talking more about like overall- - [Lex] Actual productivity. - The actual productivity, right? Engineering productivity, which is two different things,
and which is the more important metric. But I think it'll get better, right?
And like, you know, I think there's no who, tomorrow, if you magically became 2x more productive,
you're just gonna create more things, you're gonna create more value out of things. And so I think you'll find more satisfaction
in your job, right? So. - And there's a lot of aspects. I mean, the actual Google code base might just improve,
because it'll become more standardized, easier for people to move about the code base, because AI will help with that.
And therefore that will also allow the AI to understand the entire code base better, which makes the engineering aspect,
so I've been using Cursor a lot as a way to program with Gemini and other models,
it's like, one of its powerful things is it's aware of the entire code base,
and that allows you to ask questions of it, it allows the agents to move about that code base in a really powerful way.
I mean, that's a huge unlock. - Think about like, you know, migrations, refactoring old code bases.
- [Lex] Refactoring, yeah. - Yeah, I mean, think about like, you know, once we can do all this in a much better, more robust way than where we are today.
- I think in the end, everything will be written in JavaScript and run in Chrome. (Sundar laughing) I think it's all going to that direction.
I mean, just for fun, Google has legendary coding interviews,
like, rigorous interviews for the engineers. Can you comment on how that has changed in the era of AI?
It's just such a weird, (laughs) you know, the whiteboard interview I assume is not allowed to have some prompts.
- Such a good question. Look, I do think we are making sure,
you know, we'll introduce at least one round of in-person interviews for people. - [Lex] Yeah. (laughs)
- Just to make sure the fundamentals are there, I think they'll end up being important. But it's an equally important skill,
look, if you can use these tools to generate better code, like, you know, I think that's an asset.
And so, overall, I think it's a massive positive
- Vibe Coding Engineer. Do you recommend people, students interested in programming
still get an education in computer science, a college education? What do you think?
- I do. If you have a passion for computer science, I would. You know, computer science is obviously a lot more than programming alone.
So, I would. I still don't think I would change what you pursue.
I think AI will horizontally allow, impact every field,
it's pretty tough to predict in what ways, so any education in which
you're learning good first principles thinking I think is good education. - You've revolutionized web browsing,
Android
you've revolutionized a lot of things over the years. Android changed the game,
it's an incredible operating system, we could talk for hours about Android. What does the future of Android look like?
Is it possible it becomes more and more AI-centric,
especially now, throw into the mix Android XR with being able to do augmented reality, and mixed reality,
and virtual reality in the physical world? - You know, the best innovations in computing have come when you are through a paradigm IO change, right?
Like, you know, with GUI, with the Graphical User Interface, and then with multi-touch in the context of mobile,
voice later on. Similarly, I feel like, you know, AR is that next paradigm.
I think it was held back, both the system integration challenges of making good AR is very, very hard,
the second thing is, you need AI to actually kind of, otherwise the IO is too complicated,
for you to have a natural, seamless IO to that paradigm,
AI ends up being super important. And so this is why Project Astra
ends up being super critical for that Android XR world.
But it is, I think when you use glasses and, you know, always been amazed,
like at how useful these things are going to be. So look, I think it's a real opportunity for Android.
I think XR is one way it'll kind of really come to life. But I think there's an opportunity
to rethink the mobile OS too, right? I think we've been kind of living in this paradigm of like,
apps and shortcuts. All that won't go away, but again, like if you're trying to get stuff done
at an operating system level, you know, it needs to be more agentic so that you can kind of describe what you want to do,
or like proactively understands what you're trying to do, learns from how you're doing things over and over again,
and kind of is adapting to you, all that is kind of like the unlock we need to go and do.
- With the basic, efficient, minimalist UI, I've gotten a chance to try the glasses,
and they're incredible. It's the little stuff, it's hard to put into words, but no latency, it just works.
Even that little map demo where you look down, and you look up, and there's a very smooth transition between the two,
and a very small amount of useful information is shown to you,
enough not to distract from the world outside, but enough to provide a bit of context when you need it.
And some of that, in order to bring that into reality,
you have to solve a lot of the OS problems to make sure it works when you're integrating the AI into the whole thing.
So everything you do launches an agent that answers some basic question.
- Good moonshot, you know? I love that. - [Lex] Yeah. It's crazy. - No, but you know, I think we are,
but it's much closer to reality than other moonshots. You know, we expect to have glasses
in the hands of developers later this year, and in consumers' hands next year.
So it's an exciting time. - Yeah, well, extremely well-executed, Beam, all this stuff.
You know, 'cause sometimes you don't know, like somebody commented, a top comment on one of the demos of Beam, they said,
"This will either be killed off in five weeks, or revolutionize all meetings in five years."
And there's very much, Google tries so many things, and sometimes, sadly, kills off very promising projects
because there's so many other things to focus on. I use so many Google products, Google Voice, I still use,
I'm so glad that's not being killed off, that's still alive. Thank you, whoever's defending that,
'cause it's awesome. And it's great that you keep innovating. I just wanna list off, just as a big thank you.
So Search, obviously Google revolutionized. Chrome. And all of these could be multi-hour conversations.
Gmail, I've been singing Gmail praises forever. Maps, incredible technological innovation
on revolutionizing mapping. Android, like we talked about. YouTube, like we talked about. AdSense. Google Translate.
For the academic mind, Google Scholar, it's incredible, and also the scanning of the books,
so making all the world's knowledge accessible even when that knowledge is a kind of niche thing,
which Google Scholar is. And then obviously with DeepMind, with Alpha Zero,
AlphaFold, AlphaEvolve, I could talk forever about AlphaEvolve. That's mind blowing.
All of that released. And as part of that set of things you've released in this year when those brilliant articles
were written about "Google is done." And like we talked about, pioneering self-driving cars and quantum computing,
which could be another thing that is low key, is scuba diving its way to changing the world forever.
So another pothead/micro-kitchen question. (chuckles) If you build AGI,
what kind of question would you ask it? What would you want to talk about?
Definitively, Google has created AGI that can basically answer any question,
what topic are you going to? (laughs) Where are you going? - It's a great question.
Maybe it's proactive by then and should tell me a few things I should know.
But I think if I were to ask it, I think it'll help us understand ourselves much better,
in a way that'll surprise us, I think. And you already see people do it with the products,
but you know, in an AGI context, I think that'll be pretty powerful - On a personal level, or a general human nature?
- At a personal level, like you talking to AGI, I think there is some chance it'll kind of understand you
in a very deep way, I think, you know, in a profound way. That's a possibility.
I think there is also the obvious thing of like, maybe it helps us understand the universe better,
you know, in a way that expands the frontiers of our understanding of the world.
That is something super exciting. But look, I really don't know.
I haven't had access to something that powerful yet, but I think those are all possibilities.
- I think that, on the personal level, asking questions about yourself
a sequence of questions like that about what makes me happy, I think we would be very surprised to learn
through those kind of, a sequence of questions and answers,
it might explore some profound truths in a way that sometimes art reveals to us, great books reveal to us,
great conversations with loved ones reveal things that are obvious in retrospect, but are nice when they're said.
But for me, number one question is about how many alien civilizations are there? (Sundar laughing) 100%. Are they coming?
- That's gonna be your first question? - Number one, how many living and dead alien civilizations?
Maybe a bunch of follow-ups, like how close are they, are they dangerous?
If there's no alien civilizations, why? Or if there's no advanced alien civilizations,
but bacteria-like life everywhere, why? What is the barrier preventing it from getting to that?
Is it because that when you get sufficiently intelligent, you end up destroying ourselves?
Because you need competition in order to develop an advanced civilization, and when you have competitions
going to lead to military conflict, and conflict eventually kills everybody? I don't know, I'm gonna have that kind of discussion.
- You get an answer to the Fermi Paradox, yeah? - Exactly. And like have a real discussion about it.
I'm not sure, I'm realizing now with your answer, it's a more productive answer,
(Sundar laughing) 'cause I'm not sure what I'm gonna do with that information. But maybe it speaks to the general human curiosity
that Liz talked about, that we're all just really curious, and making the world's information accessible
allows our curiosity to be satiated some, with AI, even more,
we can be more and more curious, and learn more about the world, about ourselves. In so doing, and I always wonder if,
I don't know if you can comment on, like, is it possible to measure,
not the GDP productivity increase like we talked about, but maybe the whatever that increases,
the breadth and depth of human knowledge that Google has unlocked with Google Search,
and now with AI Mode with Gemini, it's a difficult thing to measure.
- Many years ago, there was, I think it was a MIT study, they just estimated the impact of Google Search,
and they basically said it's the equivalent to, on a per person basis, it's a few thousands of dollars per year, per person, right?
Like, it's the value that got created per year, right?
But yeah, it's tough to capture these things, right? Like you kind of take it for granted as these things come
and the frontier keeps moving. But, you know, how do you measure the value of something like AlphaFold over time, right?
And so on. - And also the increasing quality of life when you learn more. I have to say like,
with some of the programming I do done by AI, for some reason I'm more excited to program.
- [Sundar] Yeah. - And so the same with knowledge, with discovering things about the world,
it makes you more excited to be alive, it makes you more curious, and the more curious you are,
the more exciting it is to live and experience the world. And it's very hard to, I don't know if that makes you more productive,
probably not nearly as much as it makes you happy to be alive.
And that's a hard thing to measure, the quality of life increases some of these things do.
As AI continues to get better and better at everything that humans do, what do you think is the biggest thing that makes us humans special?
- Look, I think, it's tough, I mean, the essence of humanity,
there's something about, you know, the consciousness we have,
what makes us uniquely human, maybe the lines will blur over time, (chuckles) and it's tough to articulate.
But hopefully, you know, we live in a world where
if you make resources more plentiful, and make the world less of a zero sum game over time, right,
which it's not, but, you know, in a resource-constrained environment, people perceive it to be, right?
And so I hope the values of what makes us uniquely human,
empathy, kindness, all that, surfaces more,
is the aspirational hope I have. - Yeah, it multiplies the compassion, but also the curiosity,
just the banter, the debates we'll have about the meaning of it all. And I also think in the scientific domains,
all the incredible work that DeepMind is doing, I think we'll still continue to play,
to explore scientific questions, mathematical questions, physics questions,
even as AI gets better and better at helping us solve some of the questions.
Because sometimes the question itself is the really difficult thing. - Well, the right new questions to ask,
and the answers to them, and the self-discovery process which it'll drive, I think.
You know, our early work with both co-scientist and AlphaEvolve, just is super exciting to see.
- What gives you hope about the future of human civilization? - Look, I'm an optimist
and, you know, now, if you were to say
you take the journey of human civilization, it's been, you know, we've relentlessly made the world better, right?
In many ways, at any given moment in time, there are big issues to work through,
it may look, but, you know, I always ask myself the question, would you have been born now, or any other time in the past?
I most often, not most often, almost always would rather be born now.
Right, you know? (laughs) And so that's the extraordinary thing that human civilization has accomplished, right?
And like, you know, and we've kind of constantly made the world a better place.
And so something tells me, as humanity, we always rise collectively
to drive that frontier forward. So I expect it to be no different in the future.
- I agree with you totally. I'm truly grateful to be alive in this moment, and I'm also really excited for the future,
and the work you and incredible teams here are doing is one of the big reasons I'm excited for the future,
so thank you, thank you for all the cool products you've built, and please don't kill Google Voice. (laughs)
(Sundar laughing) Thank you. - We won't. Yeah. (laughs) (Lex laughing) - Thank you for talking today, this was incredible.
Thank you. - Real pleasure, appreciated. - Thanks for listening to this conversation with Sundar Pichai.